{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f488a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset & DataLoader helpers\n",
    "# -----------------------------\n",
    "\n",
    "class FoGWindowDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for window-level FoG data.\n",
    "\n",
    "    Expects a DataFrame with columns:\n",
    "        - 'sequence'     : (T, 3) accel window (list/array/string)\n",
    "        - 'window_label' : 0/1\n",
    "        - 'subject'      : patient ID (not used in __getitem__, but kept in df)\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def _parse_sequence(self, seq_obj):\n",
    "        # Handles numpy array, python list, or string from CSV\n",
    "        if isinstance(seq_obj, np.ndarray):\n",
    "            arr = seq_obj.astype(np.float32)\n",
    "        elif isinstance(seq_obj, list):\n",
    "            arr = np.asarray(seq_obj, dtype=np.float32)\n",
    "        else:\n",
    "            # assume string like \"[[...], [...], ...]\"\n",
    "            arr = np.array(ast.literal_eval(seq_obj), dtype=np.float32)\n",
    "\n",
    "        # Ensure shape (T, 3)\n",
    "        if arr.ndim == 1:\n",
    "            arr = arr.reshape(-1, 1)\n",
    "        return arr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        seq = self._parse_sequence(row['sequence'])  # (T, 3)\n",
    "        label = float(row['window_label'])\n",
    "\n",
    "        x = torch.from_numpy(seq)               # (T, 3)\n",
    "        y = torch.tensor(label, dtype=torch.float32)  # scalar 0/1\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def make_dataloader(df: pd.DataFrame,\n",
    "                    batch_size: int = 64,\n",
    "                    shuffle: bool = True,\n",
    "                    num_workers: int = 0) -> DataLoader:\n",
    "    dataset = FoGWindowDataset(df)\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=shuffle,\n",
    "                        num_workers=num_workers)\n",
    "    return loader\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Patient-independent folds\n",
    "# -----------------------------\n",
    "\n",
    "def create_group_kfold_splits(df: pd.DataFrame,\n",
    "                              n_splits: int = 5,\n",
    "                              random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Patient-independent K-fold splits using GroupKFold on 'subject'.\n",
    "\n",
    "    Returns a list of (train_idx, val_idx) index arrays.\n",
    "    \"\"\"\n",
    "    groups = df['subject'].values\n",
    "    y = df['window_label'].values\n",
    "    X = np.arange(len(df))\n",
    "\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    # GroupKFold is deterministic; we can shuffle subjects before if needed:\n",
    "    # but simplest is to just use GroupKFold directly.\n",
    "    splits = list(gkf.split(X, y, groups))\n",
    "    return splits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics helper\n",
    "# -----------------------------\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray,\n",
    "                    y_pred_probs: np.ndarray,\n",
    "                    threshold: float = 0.5) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute accuracy, precision, recall, F1 for binary classification.\n",
    "    \"\"\"\n",
    "    y_pred = (y_pred_probs >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='binary', zero_division=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'accuracy': float(acc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1': float(f1),\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# One epoch train / eval\n",
    "# -----------------------------\n",
    "\n",
    "def run_epoch(model: nn.Module,\n",
    "              loader: DataLoader,\n",
    "              criterion,\n",
    "              device: torch.device,\n",
    "              optimizer=None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    If optimizer is provided: training mode.\n",
    "    Otherwise: evaluation mode.\n",
    "\n",
    "    Returns dict: loss, accuracy, precision, recall, f1\n",
    "    \"\"\"\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "    else:\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "    all_losses = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)              # (batch, T, 3)\n",
    "        y = y.to(device)              # (batch,)\n",
    "\n",
    "        logits = model(x)             # (batch,)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        all_losses.append(loss.item())\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        all_probs.append(probs.detach().cpu().numpy())\n",
    "        all_labels.append(y.detach().cpu().numpy())\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    metrics = compute_metrics(all_labels, all_probs)\n",
    "    metrics['loss'] = float(np.mean(all_losses))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training one fold (with early stopping & scheduler)\n",
    "# -----------------------------\n",
    "\n",
    "def train_one_fold(\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    input_dim: int = 3,\n",
    "    hidden_dim: int = 128,\n",
    "    num_layers: int = 2,\n",
    "    bidirectional: bool = False,\n",
    "    dropout: float = 0.0,\n",
    "    batch_size: int = 16,\n",
    "    num_epochs: int = 50,\n",
    "    lr: float = 1e-4,\n",
    "    weight_decay: float = 1e-4,\n",
    "    early_stopping_patience: int = 7,\n",
    "    device: str = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Train LSTM on one fold with early stopping on val F1 and\n",
    "    ReduceLROnPlateau scheduler on val loss.\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'best_state_dict'\n",
    "            - 'history' : list of per-epoch metrics\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = make_dataloader(train_df, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = make_dataloader(val_df, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model, loss, optimizer, scheduler\n",
    "    #model =  ParallelCNNLSTMTransformer().to(device)\n",
    "    # ---------------------------\n",
    "    # Quick test\n",
    "    # ---------------------------\n",
    "\n",
    "    B = 4\n",
    "    T = 256\n",
    "    C = 3\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = CNN_Transformer_Model().to(device)\n",
    "\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    #criterion = WeightedBCEWithLogitsLoss()\n",
    "    #criterion = FocalTverskyLoss(gamma=0.75, alpha=0.7)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5\n",
    "    )\n",
    "\n",
    "    best_val_f1 = -np.inf\n",
    "    best_state_dict = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    history = []  # list of dicts per epoch\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # --- Train ---\n",
    "        train_metrics = run_epoch(model, train_loader, criterion, device, optimizer)\n",
    "\n",
    "        # --- Validation ---\n",
    "        val_metrics = run_epoch(model, val_loader, criterion, device, optimizer=None)\n",
    "\n",
    "        # Step scheduler on validation loss\n",
    "        scheduler.step(val_metrics['loss'])\n",
    "\n",
    "        # Early stopping on val F1\n",
    "        val_f1 = val_metrics['f1']\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_state_dict = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        # Record metrics\n",
    "        epoch_record = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_metrics['loss'],\n",
    "            'train_accuracy': train_metrics['accuracy'],\n",
    "            'train_precision': train_metrics['precision'],\n",
    "            'train_recall': train_metrics['recall'],\n",
    "            'train_f1': train_metrics['f1'],\n",
    "            'val_loss': val_metrics['loss'],\n",
    "            'val_accuracy': val_metrics['accuracy'],\n",
    "            'val_precision': val_metrics['precision'],\n",
    "            'val_recall': val_metrics['recall'],\n",
    "            'val_f1': val_metrics['f1'],\n",
    "            'lr': optimizer.param_groups[0]['lr'],\n",
    "        }\n",
    "        history.append(epoch_record)\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch:02d}] \"\n",
    "            f\"Train Loss={train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}, F1={train_metrics['f1']:.4f} | \"\n",
    "\n",
    "            f\"Val Loss={val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f} F1={val_metrics['f1']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if epochs_without_improvement >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch} (no val F1 improvement for \"\n",
    "                  f\"{early_stopping_patience} epochs).\")\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'best_state_dict': best_state_dict,\n",
    "        'history': history,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "def summarize_and_save_cv_results(\n",
    "        results: Dict[str, Any],\n",
    "        output_prefix: str = \"cv_results\",\n",
    "        save_best_model_path: str = \"best_model_overall.pt\",\n",
    "        save_all_folds_dir: str = \"all_best_models\"):\n",
    "    \"\"\"\n",
    "    - Extract best metrics from each fold\n",
    "    - Compute mean and std\n",
    "    - Save fold-wise results and summary to Excel\n",
    "    - Save ALL best model weights for all folds\n",
    "    - Save the global best model across folds\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    os.makedirs(save_all_folds_dir, exist_ok=True)\n",
    "\n",
    "    fold_best_rows = []\n",
    "    global_best_f1 = -np.inf\n",
    "    global_best_state_dict = None\n",
    "    global_best_fold = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # Extract best epoch per fold\n",
    "    # -----------------------------\n",
    "    for fold_data in results['folds']:\n",
    "        fold_idx = fold_data['fold_idx']\n",
    "        history = fold_data['history']\n",
    "\n",
    "        # Best epoch based on val_f1\n",
    "        best_epoch_record = max(history, key=lambda x: x['val_f1'])\n",
    "\n",
    "        row = {\n",
    "            'fold': fold_idx,\n",
    "            'val_accuracy': best_epoch_record['val_accuracy'],\n",
    "            'val_precision': best_epoch_record['val_precision'],\n",
    "            'val_recall': best_epoch_record['val_recall'],\n",
    "            'val_f1': best_epoch_record['val_f1'],\n",
    "            'val_loss': best_epoch_record['val_loss'],\n",
    "        }\n",
    "\n",
    "        fold_best_rows.append(row)\n",
    "\n",
    "        # ---------------------------------------\n",
    "        # Save THIS FOLD'S best model separately\n",
    "        # ---------------------------------------\n",
    "        fold_model_path = os.path.join(\n",
    "            save_all_folds_dir, f\"best_model_fold_{fold_idx}.pt\"\n",
    "        )\n",
    "        torch.save(fold_data['best_state_dict'], fold_model_path)\n",
    "        print(f\" Saved best model for Fold {fold_idx} ‚Üí {fold_model_path}\")\n",
    "\n",
    "        # ---------------------------------------\n",
    "        # Track the GLOBAL best model\n",
    "        # ---------------------------------------\n",
    "        if best_epoch_record['val_f1'] > global_best_f1:\n",
    "            global_best_f1 = best_epoch_record['val_f1']\n",
    "            global_best_state_dict = fold_data['best_state_dict']\n",
    "            global_best_fold = fold_idx\n",
    "\n",
    "    df_folds = pd.DataFrame(fold_best_rows)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Mean & Std\n",
    "    # -----------------------------\n",
    "    summary = {}\n",
    "    for col in ['val_accuracy', 'val_precision', 'val_recall', 'val_f1', 'val_loss']:\n",
    "        summary[f'{col}_mean'] = df_folds[col].mean()\n",
    "        summary[f'{col}_std'] = df_folds[col].std()\n",
    "\n",
    "    df_summary = pd.DataFrame([summary])\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save Excel files\n",
    "    # -----------------------------\n",
    "    folds_excel = f\"{output_prefix}_folds.xlsx\"\n",
    "    summary_excel = f\"{output_prefix}_summary.xlsx\"\n",
    "\n",
    "    df_folds.to_excel(folds_excel, index=False)\n",
    "    df_summary.to_excel(summary_excel, index=False)\n",
    "\n",
    "    print(f\" Fold metrics saved to Excel: {folds_excel}\")\n",
    "    print(f\" Summary metrics saved to Excel: {summary_excel}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save global best model\n",
    "    # -----------------------------\n",
    "    if global_best_state_dict is not None:\n",
    "        torch.save(global_best_state_dict, save_best_model_path)\n",
    "        print(f\"üèÜ Global best model (Fold {global_best_fold}) saved ‚Üí {save_best_model_path}\")\n",
    "\n",
    "    return {\n",
    "        'fold_metrics_df': df_folds,\n",
    "        'summary_df': df_summary,\n",
    "        'best_fold': global_best_fold,\n",
    "        'best_f1': global_best_f1\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Full K-fold cross-validation\n",
    "# -----------------------------\n",
    "\n",
    "def cross_validate_patient_independent(\n",
    "    df: pd.DataFrame,\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    "    **train_kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run patient-independent K-fold cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          'folds': [\n",
    "            {\n",
    "              'fold_idx': 0,\n",
    "              'train_subjects': [...],\n",
    "              'val_subjects': [...],\n",
    "              'history': [...],           # list of per-epoch dicts\n",
    "              'best_state_dict': {...},\n",
    "            },\n",
    "            ...\n",
    "          ]\n",
    "        }\n",
    "    \"\"\"\n",
    "    splits = create_group_kfold_splits(df, n_splits=n_splits, random_state=random_state)\n",
    "\n",
    "    results = {'folds': []}\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(splits):\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Fold {fold_idx + 1}/{n_splits}\")\n",
    "\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        train_subjects = sorted(train_df['subject'].unique())\n",
    "        val_subjects = sorted(val_df['subject'].unique())\n",
    "\n",
    "        print(f\"Train subjects (n={len(train_subjects)}): {train_subjects}\")\n",
    "        print(f\"Val subjects   (n={len(val_subjects)}): {val_subjects}\")\n",
    "        print(f\"Train windows: {len(train_df)}, Val windows: {len(val_df)}\")\n",
    "\n",
    "        fold_result = train_one_fold(\n",
    "            train_df=train_df,\n",
    "            val_df=val_df,\n",
    "            **train_kwargs\n",
    "        )\n",
    "\n",
    "        results['folds'].append({\n",
    "            'fold_idx': fold_idx,\n",
    "            'train_subjects': train_subjects,\n",
    "            'val_subjects': val_subjects,\n",
    "            'history': fold_result['history'],\n",
    "            'best_state_dict': fold_result['best_state_dict'],\n",
    "        })\n",
    "    #save the results:\n",
    "    summary = summarize_and_save_cv_results(\n",
    "        results,\n",
    "        output_prefix=\"fog_cv\",\n",
    "        save_best_model_path=\"best_fog_model.pt\"\n",
    "    )\n",
    "\n",
    "    results['summary'] = summary\n",
    "\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bbc5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ecf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. AttentionLayer (No Change) ---\n",
    "class AttentionLayer(nn.Module):\n",
    "    \"\"\"Attention mechanism for global context pooling.\"\"\"\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, hidden_dim)\n",
    "        scores = torch.relu(self.attention(x)) \n",
    "        weights = F.softmax(scores.squeeze(-1), dim=1) \n",
    "        context = torch.sum(x * weights.unsqueeze(-1), dim=1) \n",
    "        return context\n",
    "\n",
    "\n",
    "\n",
    "                       # sequence of features per timestep\n",
    "    \n",
    "# CNN BRANCH WITH SKIP\n",
    "# =========================\n",
    "class CNNBranch(nn.Module):\n",
    "    def __init__(self, in_ch=3, channels=[64, 128, 128], kernel_size=5, skip=True):\n",
    "        super().__init__()\n",
    "        self.skip = skip\n",
    "        layers = []\n",
    "        ch = in_ch\n",
    "        for out_ch in channels:\n",
    "            layers.append(nn.Sequential(\n",
    "                nn.Conv1d(ch, out_ch, kernel_size, padding=kernel_size//2),\n",
    "                nn.BatchNorm1d(out_ch),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "            ch = out_ch\n",
    "        self.blocks = nn.ModuleList(layers)\n",
    "        self.out_channels = ch\n",
    "\n",
    "        if skip and in_ch != ch:\n",
    "            self.skip_proj = nn.Conv1d(in_ch, ch, kernel_size=1)\n",
    "        else:\n",
    "            self.skip_proj = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        residual_input = x\n",
    "        out = x\n",
    "\n",
    "        for block in self.blocks:\n",
    "            prev = out\n",
    "            out = block(out)\n",
    "            if self.skip and prev.shape == out.shape:\n",
    "                out = out + prev\n",
    "\n",
    "        if self.skip and self.skip_proj is not None:\n",
    "            residual_input = self.skip_proj(residual_input)\n",
    "            out = out + residual_input\n",
    "\n",
    "        return out.permute(0, 2, 1)  # (B, T, D_cnn)\n",
    "# ---------------------------\n",
    "# Shared Transformer (fusion) with optional causal mask\n",
    "# ---------------------------\n",
    "class SharedTransformerFusion(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads=8, ff_mult=2, dropout=0.1, use_causal_mask=False):\n",
    "        \"\"\"\n",
    "        embed_dim: embedding dimension per token (here token dim is 2E because we concat projections)\n",
    "        use_causal_mask: if True, transformer attention is masked so each time step attends only to the past (and itself)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.use_causal_mask = use_causal_mask\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ln1 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * ff_mult),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(embed_dim * ff_mult, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        self.ln2 = nn.LayerNorm(embed_dim, eps=1e-6)\n",
    "\n",
    "    def _causal_mask(self, T, device):\n",
    "        # returns additive mask of shape (T, T) with -inf in upper triangle (j > i)\n",
    "        mask = torch.triu(torch.ones(T, T, device=device) * float('-inf'), diagonal=1)\n",
    "        return mask\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, embed_dim)\n",
    "        B, T, D = x.shape\n",
    "        attn_mask = None\n",
    "        if self.use_causal_mask:\n",
    "            attn_mask = self._causal_mask(T, x.device)  # shape (T, T) acceptable by MultiheadAttention\n",
    "        attn_out, _ = self.attn(x, x, x, attn_mask=attn_mask)\n",
    "        x = self.ln1(x + attn_out)\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.ln2(x + ff_out)\n",
    "        return x  # (B, T, embed_dim)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CNN_Transformer_Model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 seq_len=256,\n",
    "                 in_channels=3,\n",
    "                 tcn_channels=[32, 64, 128, 128],\n",
    "                 tcn_kernel=3,\n",
    "                 lstm_hidden=96,\n",
    "                 lstm_layers=2,\n",
    "                 proj_embed=64,          # E\n",
    "                 transformer_heads=4,\n",
    "                 transformer_ffmult=2,\n",
    "                 transformer_dropout=0.2,\n",
    "                 use_causal_transformer=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # === Branches ===\n",
    "        self.cnn = CNNBranch(in_ch=in_channels)\n",
    "\n",
    "        # === Projection to shared embedding E ===\n",
    "        self.proj_cnn = nn.Linear(self.cnn.out_channels, proj_embed)\n",
    "       \n",
    "\n",
    "        # === Shared Transformer: receives 2E features ===\n",
    "        embed_dim = 1 * proj_embed\n",
    "        self.shared_transformer = SharedTransformerFusion(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=transformer_heads,\n",
    "            ff_mult=transformer_ffmult,\n",
    "            dropout=transformer_dropout,\n",
    "            use_causal_mask=use_causal_transformer\n",
    "        )\n",
    "\n",
    "        # ===  Attention pooling instead of GlobalAveragePool ===\n",
    "        self.attention = AttentionLayer(hidden_dim=embed_dim)\n",
    "\n",
    "        # === Final classifier ===\n",
    "        self.pool_dropout = nn.Dropout(0.2)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(embed_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        x = x.permute(0, 2, 1)     # -> (B, T, C)\n",
    "\n",
    "        # Branches\n",
    "        f_cnn = self.cnn(x)        # (B, T, D1)\n",
    " \n",
    "\n",
    "\n",
    "        f_cnn = self.proj_cnn(f_cnn)\n",
    "\n",
    "        # Fusion: (B, T, 2E)\n",
    "\n",
    "\n",
    "        # Transformer encoding\n",
    "        z = self.shared_transformer(f_cnn)    # (B, T, 2E)\n",
    "\n",
    "        # ===  Attention pooling (replace mean pooling) ===\n",
    "        context = self.attention(z)           # (B, 2E)\n",
    "        context = self.pool_dropout(context)\n",
    "\n",
    "        out = self.mlp(context).squeeze(-1)   # (B,)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c179b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Student\\\\Desktop\\\\Abouhashem\\\\DeepLearningProject\\\\'\n",
    "train_df = pd.read_pickle(path+ \"FoG_windows_train.pkl\")\n",
    "test_df  = pd.read_pickle(path+\"FoG_windows_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17cc619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Fold 1/5\n",
      "Train subjects (n=32): ['07285e', '194d1d', '220a17', '231c3b', '24a59d', '251738', '2a39f8', '2c98f7', '31d269', '364459', '3b2403', '48fd62', '4b39ac', '4ca9b3', '4f13b4', '516a67', '54ee6e', '66341b', '7688c1', '79011a', '7eb666', '7fcee9', '8db7dd', '93f49f', 'a03db7', 'bc3908', 'c85fdf', 'c8e721', 'd8836b', 'd9312a', 'e8919c', 'f2c8aa']\n",
      "Val subjects   (n=2): ['2d57c2', '87174c']\n",
      "Train windows: 15896, Val windows: 3984\n",
      "[Epoch 01] Train Loss=0.4850, Acc: 0.7653, F1=0.4275 | Val Loss=0.9971, Acc: 0.4465 F1=0.5564\n",
      "[Epoch 02] Train Loss=0.4037, Acc: 0.8171, F1=0.6181 | Val Loss=0.6221, Acc: 0.7058 F1=0.8061\n",
      "[Epoch 03] Train Loss=0.3600, Acc: 0.8412, F1=0.6808 | Val Loss=1.4972, Acc: 0.3446 F1=0.4275\n",
      "[Epoch 04] Train Loss=0.3258, Acc: 0.8607, F1=0.7250 | Val Loss=0.6922, Acc: 0.7058 F1=0.8059\n",
      "[Epoch 05] Train Loss=0.3068, Acc: 0.8705, F1=0.7509 | Val Loss=0.8036, Acc: 0.6155 F1=0.7293\n",
      "[Epoch 06] Train Loss=0.2921, Acc: 0.8741, F1=0.7580 | Val Loss=1.2214, Acc: 0.4613 F1=0.5732\n",
      "[Epoch 07] Train Loss=0.2822, Acc: 0.8817, F1=0.7726 | Val Loss=0.8711, Acc: 0.6225 F1=0.7352\n",
      "[Epoch 08] Train Loss=0.2686, Acc: 0.8877, F1=0.7859 | Val Loss=1.0954, Acc: 0.5497 F1=0.6674\n",
      "[Epoch 09] Train Loss=0.2544, Acc: 0.8949, F1=0.8002 | Val Loss=0.8994, Acc: 0.6739 F1=0.7800\n",
      "Early stopping at epoch 9 (no val F1 improvement for 7 epochs).\n",
      "============================================================\n",
      "Fold 2/5\n",
      "Train subjects (n=26): ['07285e', '220a17', '24a59d', '2c98f7', '2d57c2', '31d269', '364459', '3b2403', '48fd62', '4b39ac', '4ca9b3', '516a67', '54ee6e', '66341b', '79011a', '7eb666', '7fcee9', '87174c', '8db7dd', '93f49f', 'a03db7', 'bc3908', 'c8e721', 'd8836b', 'd9312a', 'e8919c']\n",
      "Val subjects   (n=8): ['194d1d', '231c3b', '251738', '2a39f8', '4f13b4', '7688c1', 'c85fdf', 'f2c8aa']\n",
      "Train windows: 15880, Val windows: 4000\n",
      "[Epoch 01] Train Loss=0.4295, Acc: 0.8084, F1=0.7283 | Val Loss=0.7233, Acc: 0.6458 F1=0.4348\n",
      "[Epoch 02] Train Loss=0.3370, Acc: 0.8575, F1=0.8069 | Val Loss=0.7206, Acc: 0.6450 F1=0.3689\n",
      "[Epoch 03] Train Loss=0.3000, Acc: 0.8749, F1=0.8323 | Val Loss=0.4528, Acc: 0.7835 F1=0.6715\n",
      "[Epoch 04] Train Loss=0.2806, Acc: 0.8816, F1=0.8428 | Val Loss=0.4137, Acc: 0.8107 F1=0.7256\n",
      "[Epoch 05] Train Loss=0.2660, Acc: 0.8890, F1=0.8531 | Val Loss=0.4059, Acc: 0.8263 F1=0.7552\n",
      "[Epoch 06] Train Loss=0.2500, Acc: 0.8973, F1=0.8650 | Val Loss=0.6490, Acc: 0.7490 F1=0.6075\n",
      "[Epoch 07] Train Loss=0.2427, Acc: 0.8984, F1=0.8666 | Val Loss=0.6263, Acc: 0.7195 F1=0.5100\n",
      "[Epoch 08] Train Loss=0.2336, Acc: 0.9052, F1=0.8757 | Val Loss=0.4152, Acc: 0.8183 F1=0.7357\n",
      "[Epoch 09] Train Loss=0.2209, Acc: 0.9095, F1=0.8818 | Val Loss=0.3469, Acc: 0.8570 F1=0.8122\n",
      "[Epoch 10] Train Loss=0.2226, Acc: 0.9072, F1=0.8789 | Val Loss=0.4746, Acc: 0.8130 F1=0.7374\n",
      "[Epoch 11] Train Loss=0.2143, Acc: 0.9101, F1=0.8824 | Val Loss=0.4566, Acc: 0.7957 F1=0.6953\n",
      "[Epoch 12] Train Loss=0.2107, Acc: 0.9138, F1=0.8873 | Val Loss=0.3695, Acc: 0.8548 F1=0.8093\n",
      "[Epoch 13] Train Loss=0.2016, Acc: 0.9168, F1=0.8915 | Val Loss=0.5689, Acc: 0.7833 F1=0.6630\n",
      "[Epoch 14] Train Loss=0.1966, Acc: 0.9185, F1=0.8937 | Val Loss=0.4298, Acc: 0.8285 F1=0.7625\n",
      "[Epoch 15] Train Loss=0.1940, Acc: 0.9202, F1=0.8959 | Val Loss=0.4124, Acc: 0.8260 F1=0.7578\n",
      "[Epoch 16] Train Loss=0.1773, Acc: 0.9290, F1=0.9078 | Val Loss=0.3293, Acc: 0.8748 F1=0.8391\n",
      "[Epoch 17] Train Loss=0.1694, Acc: 0.9330, F1=0.9128 | Val Loss=0.3522, Acc: 0.8612 F1=0.8215\n",
      "[Epoch 18] Train Loss=0.1661, Acc: 0.9336, F1=0.9139 | Val Loss=0.3455, Acc: 0.8658 F1=0.8259\n",
      "[Epoch 19] Train Loss=0.1632, Acc: 0.9356, F1=0.9164 | Val Loss=0.3341, Acc: 0.8780 F1=0.8420\n",
      "[Epoch 20] Train Loss=0.1605, Acc: 0.9348, F1=0.9154 | Val Loss=0.4011, Acc: 0.8363 F1=0.7750\n",
      "[Epoch 21] Train Loss=0.1560, Acc: 0.9373, F1=0.9186 | Val Loss=0.3644, Acc: 0.8528 F1=0.8110\n",
      "[Epoch 22] Train Loss=0.1547, Acc: 0.9375, F1=0.9188 | Val Loss=0.3119, Acc: 0.8780 F1=0.8491\n",
      "[Epoch 23] Train Loss=0.1509, Acc: 0.9397, F1=0.9218 | Val Loss=0.3511, Acc: 0.8720 F1=0.8351\n",
      "[Epoch 24] Train Loss=0.1510, Acc: 0.9397, F1=0.9219 | Val Loss=0.3142, Acc: 0.8750 F1=0.8520\n",
      "[Epoch 25] Train Loss=0.1443, Acc: 0.9431, F1=0.9261 | Val Loss=0.4192, Acc: 0.8423 F1=0.7865\n",
      "[Epoch 26] Train Loss=0.1417, Acc: 0.9413, F1=0.9241 | Val Loss=0.3743, Acc: 0.8612 F1=0.8156\n",
      "[Epoch 27] Train Loss=0.1399, Acc: 0.9452, F1=0.9290 | Val Loss=0.4081, Acc: 0.8417 F1=0.7877\n",
      "[Epoch 28] Train Loss=0.1381, Acc: 0.9447, F1=0.9283 | Val Loss=0.4017, Acc: 0.8455 F1=0.7923\n",
      "[Epoch 29] Train Loss=0.1254, Acc: 0.9509, F1=0.9363 | Val Loss=0.3602, Acc: 0.8620 F1=0.8253\n",
      "[Epoch 30] Train Loss=0.1212, Acc: 0.9533, F1=0.9395 | Val Loss=0.4659, Acc: 0.8143 F1=0.7428\n",
      "[Epoch 31] Train Loss=0.1185, Acc: 0.9536, F1=0.9400 | Val Loss=0.4372, Acc: 0.8353 F1=0.7755\n",
      "Early stopping at epoch 31 (no val F1 improvement for 7 epochs).\n",
      "============================================================\n",
      "Fold 3/5\n",
      "Train subjects (n=26): ['194d1d', '220a17', '231c3b', '24a59d', '251738', '2a39f8', '2c98f7', '2d57c2', '31d269', '4b39ac', '4ca9b3', '4f13b4', '516a67', '7688c1', '79011a', '7eb666', '7fcee9', '87174c', '8db7dd', 'a03db7', 'bc3908', 'c85fdf', 'c8e721', 'd8836b', 'e8919c', 'f2c8aa']\n",
      "Val subjects   (n=8): ['07285e', '364459', '3b2403', '48fd62', '54ee6e', '66341b', '93f49f', 'd9312a']\n",
      "Train windows: 15909, Val windows: 3971\n",
      "[Epoch 01] Train Loss=0.4544, Acc: 0.7802, F1=0.7497 | Val Loss=0.4479, Acc: 0.7988 F1=0.3733\n",
      "[Epoch 02] Train Loss=0.3460, Acc: 0.8489, F1=0.8293 | Val Loss=0.4203, Acc: 0.8318 F1=0.3013\n",
      "[Epoch 03] Train Loss=0.2993, Acc: 0.8764, F1=0.8617 | Val Loss=0.4415, Acc: 0.7978 F1=0.3866\n",
      "[Epoch 04] Train Loss=0.2710, Acc: 0.8937, F1=0.8812 | Val Loss=0.4395, Acc: 0.7965 F1=0.4278\n",
      "[Epoch 05] Train Loss=0.2558, Acc: 0.8992, F1=0.8878 | Val Loss=0.4318, Acc: 0.8101 F1=0.4227\n",
      "[Epoch 06] Train Loss=0.2438, Acc: 0.9040, F1=0.8937 | Val Loss=0.4201, Acc: 0.8421 F1=0.3895\n",
      "[Epoch 07] Train Loss=0.2314, Acc: 0.9094, F1=0.8995 | Val Loss=0.4351, Acc: 0.8318 F1=0.3769\n",
      "[Epoch 08] Train Loss=0.2244, Acc: 0.9119, F1=0.9021 | Val Loss=0.4255, Acc: 0.8356 F1=0.3926\n",
      "[Epoch 09] Train Loss=0.2174, Acc: 0.9173, F1=0.9082 | Val Loss=0.4112, Acc: 0.8348 F1=0.3811\n",
      "[Epoch 10] Train Loss=0.2126, Acc: 0.9173, F1=0.9082 | Val Loss=0.3990, Acc: 0.8348 F1=0.4036\n",
      "[Epoch 11] Train Loss=0.2062, Acc: 0.9216, F1=0.9130 | Val Loss=0.4164, Acc: 0.8215 F1=0.4174\n",
      "Early stopping at epoch 11 (no val F1 improvement for 7 epochs).\n",
      "============================================================\n",
      "Fold 4/5\n",
      "Train subjects (n=26): ['07285e', '194d1d', '220a17', '231c3b', '251738', '2a39f8', '2c98f7', '2d57c2', '31d269', '364459', '3b2403', '48fd62', '4f13b4', '516a67', '54ee6e', '66341b', '7688c1', '7fcee9', '87174c', '93f49f', 'a03db7', 'bc3908', 'c85fdf', 'd9312a', 'e8919c', 'f2c8aa']\n",
      "Val subjects   (n=8): ['24a59d', '4b39ac', '4ca9b3', '79011a', '7eb666', '8db7dd', 'c8e721', 'd8836b']\n",
      "Train windows: 15916, Val windows: 3964\n",
      "[Epoch 01] Train Loss=0.4517, Acc: 0.7842, F1=0.7158 | Val Loss=0.3898, Acc: 0.8244 F1=0.7051\n",
      "[Epoch 02] Train Loss=0.3337, Acc: 0.8545, F1=0.8176 | Val Loss=0.3525, Acc: 0.8451 F1=0.7473\n",
      "[Epoch 03] Train Loss=0.2903, Acc: 0.8785, F1=0.8497 | Val Loss=0.3484, Acc: 0.8610 F1=0.7901\n",
      "[Epoch 04] Train Loss=0.2678, Acc: 0.8891, F1=0.8634 | Val Loss=0.3349, Acc: 0.8623 F1=0.7976\n",
      "[Epoch 05] Train Loss=0.2571, Acc: 0.8958, F1=0.8714 | Val Loss=0.3158, Acc: 0.8650 F1=0.7876\n",
      "[Epoch 06] Train Loss=0.2437, Acc: 0.9008, F1=0.8780 | Val Loss=0.3128, Acc: 0.8635 F1=0.7863\n",
      "[Epoch 07] Train Loss=0.2317, Acc: 0.9063, F1=0.8849 | Val Loss=0.3140, Acc: 0.8713 F1=0.7968\n",
      "[Epoch 08] Train Loss=0.2233, Acc: 0.9094, F1=0.8892 | Val Loss=0.3238, Acc: 0.8635 F1=0.7741\n",
      "[Epoch 09] Train Loss=0.2154, Acc: 0.9095, F1=0.8894 | Val Loss=0.3192, Acc: 0.8676 F1=0.7769\n",
      "[Epoch 10] Train Loss=0.2069, Acc: 0.9147, F1=0.8958 | Val Loss=0.3302, Acc: 0.8618 F1=0.7686\n",
      "[Epoch 11] Train Loss=0.2055, Acc: 0.9161, F1=0.8973 | Val Loss=0.3214, Acc: 0.8698 F1=0.7897\n",
      "Early stopping at epoch 11 (no val F1 improvement for 7 epochs).\n",
      "============================================================\n",
      "Fold 5/5\n",
      "Train subjects (n=26): ['07285e', '194d1d', '231c3b', '24a59d', '251738', '2a39f8', '2d57c2', '364459', '3b2403', '48fd62', '4b39ac', '4ca9b3', '4f13b4', '54ee6e', '66341b', '7688c1', '79011a', '7eb666', '87174c', '8db7dd', '93f49f', 'c85fdf', 'c8e721', 'd8836b', 'd9312a', 'f2c8aa']\n",
      "Val subjects   (n=8): ['220a17', '2c98f7', '31d269', '516a67', '7fcee9', 'a03db7', 'bc3908', 'e8919c']\n",
      "Train windows: 15919, Val windows: 3961\n",
      "[Epoch 01] Train Loss=0.4602, Acc: 0.7766, F1=0.7394 | Val Loss=0.4163, Acc: 0.8271 F1=0.6083\n",
      "[Epoch 02] Train Loss=0.3282, Acc: 0.8631, F1=0.8445 | Val Loss=0.3673, Acc: 0.8394 F1=0.5726\n",
      "[Epoch 03] Train Loss=0.2911, Acc: 0.8805, F1=0.8649 | Val Loss=0.4165, Acc: 0.8134 F1=0.5888\n",
      "[Epoch 04] Train Loss=0.2764, Acc: 0.8871, F1=0.8730 | Val Loss=0.4185, Acc: 0.8084 F1=0.5734\n",
      "[Epoch 05] Train Loss=0.2609, Acc: 0.8924, F1=0.8788 | Val Loss=0.4889, Acc: 0.7811 F1=0.5658\n",
      "[Epoch 06] Train Loss=0.2545, Acc: 0.8970, F1=0.8844 | Val Loss=0.3755, Acc: 0.8266 F1=0.5767\n",
      "[Epoch 07] Train Loss=0.2437, Acc: 0.8991, F1=0.8870 | Val Loss=0.4737, Acc: 0.7746 F1=0.5607\n",
      "[Epoch 08] Train Loss=0.2333, Acc: 0.9065, F1=0.8952 | Val Loss=0.4097, Acc: 0.8104 F1=0.5880\n",
      "Early stopping at epoch 8 (no val F1 improvement for 7 epochs).\n",
      "üìÅ Saved best model for Fold 0 ‚Üí all_best_models\\best_model_fold_0.pt\n",
      "üìÅ Saved best model for Fold 1 ‚Üí all_best_models\\best_model_fold_1.pt\n",
      "üìÅ Saved best model for Fold 2 ‚Üí all_best_models\\best_model_fold_2.pt\n",
      "üìÅ Saved best model for Fold 3 ‚Üí all_best_models\\best_model_fold_3.pt\n",
      "üìÅ Saved best model for Fold 4 ‚Üí all_best_models\\best_model_fold_4.pt\n",
      "‚úÖ Fold metrics saved to Excel: fog_cv_folds.xlsx\n",
      "‚úÖ Summary metrics saved to Excel: fog_cv_summary.xlsx\n",
      "üèÜ Global best model (Fold 1) saved ‚Üí best_fog_model.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_results = cross_validate_patient_independent(\n",
    "    train_df,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    input_dim=3,\n",
    "    hidden_dim=64,\n",
    "    num_layers=1,\n",
    "    bidirectional=False,\n",
    "    dropout=0.2,\n",
    "    batch_size=16,\n",
    "    num_epochs=50,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    early_stopping_patience=7,\n",
    "    device=None,  # auto: cuda if available else cpu\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e820ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evaluate_models_on_test_ensemble(\n",
    "    test_df: pd.DataFrame,\n",
    "    model_paths: List[str],\n",
    "    batch_size: int = 32,\n",
    "    device: str = None,\n",
    "    fold_weights: List[float] = None   # OPTIONAL for weighted voting\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate an ensemble of models on the test set using:\n",
    "        - Soft voting (default)\n",
    "        - Hard majority voting\n",
    "        - Optional weighted voting\n",
    "\n",
    "    Args:\n",
    "        test_df        : Test dataframe\n",
    "        model_paths    : List of paths to saved fold models\n",
    "        batch_size     : Test batch size\n",
    "        device         : 'cpu' or 'cuda'\n",
    "        fold_weights   : Optional weights per fold (e.g. fold F1)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with all ensemble metrics and voting predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # Device Setup\n",
    "    # -----------------------------\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # -----------------------------\n",
    "    # DataLoader\n",
    "    # -----------------------------\n",
    "    test_loader = make_dataloader(test_df, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # collect predictions from each model\n",
    "    prob_list = []     # soft voting\n",
    "    hard_list = []     # hard voting\n",
    "    targets_list = []\n",
    "\n",
    "    # -----------------------------\n",
    "    # Load each model and predict\n",
    "    # -----------------------------\n",
    "    for idx, model_path in enumerate(model_paths):\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\" Model not found: {model_path}\")\n",
    "\n",
    "        print(f\" Loading model: {model_path}\")\n",
    "\n",
    "        model = CNN_Transformer_Model().to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        fold_probs = []\n",
    "        fold_hard = []\n",
    "        fold_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                logits = model(X)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "\n",
    "                preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "                fold_probs.extend(probs)\n",
    "                fold_hard.extend(preds)\n",
    "                fold_targets.extend(y.cpu().numpy().astype(int))\n",
    "\n",
    "        prob_list.append(np.array(fold_probs))\n",
    "        hard_list.append(np.array(fold_hard))\n",
    "        targets_list = fold_targets     # same for all folds\n",
    "\n",
    "    prob_matrix = np.vstack(prob_list)     # shape: (num_models, N)\n",
    "    hard_matrix = np.vstack(hard_list)     # shape: (num_models, N)\n",
    "    ground_truth = np.array(targets_list)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Voting Methods\n",
    "    # -----------------------------\n",
    "\n",
    "    # SOFT VOTING (best default)\n",
    "    soft_probs = prob_matrix.mean(axis=0)\n",
    "    soft_preds = (soft_probs >= 0.5).astype(int)\n",
    "\n",
    "    # HARD VOTING\n",
    "    hard_preds = np.round(hard_matrix.mean(axis=0)).astype(int)\n",
    "\n",
    "    # WEIGHTED VOTING (if provided)\n",
    "    if fold_weights is not None:\n",
    "        w = np.array(fold_weights).reshape(-1, 1)\n",
    "        weighted_probs = (prob_matrix * w).sum(axis=0) / w.sum()\n",
    "        weighted_preds = (weighted_probs >= 0.5).astype(int)\n",
    "    else:\n",
    "        weighted_preds = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # Metric Function\n",
    "    # -----------------------------\n",
    "    def compute_metrics(preds, probs=None):\n",
    "        return {\n",
    "            \"loss\": criterion(\n",
    "                torch.tensor(preds, dtype=torch.float32),\n",
    "                torch.tensor(ground_truth, dtype=torch.float32)\n",
    "            ).item(),\n",
    "            \"accuracy\": accuracy_score(ground_truth, preds),\n",
    "            \"precision\": precision_score(ground_truth, preds, zero_division=0),\n",
    "            \"recall\": recall_score(ground_truth, preds, zero_division=0),\n",
    "            \"f1\": f1_score(ground_truth, preds, zero_division=0),\n",
    "            \"roc_auc\": roc_auc_score(ground_truth, probs) if probs is not None else None,\n",
    "            \"pr_auc\": average_precision_score(ground_truth, probs) if probs is not None else None,\n",
    "            \"confusion_matrix\": confusion_matrix(ground_truth, preds)\n",
    "        }\n",
    "\n",
    "    # -----------------------------\n",
    "    # Compute Metrics\n",
    "    # -----------------------------\n",
    "    metrics_soft = compute_metrics(soft_preds, soft_probs)\n",
    "    metrics_hard = compute_metrics(hard_preds, soft_probs)\n",
    "    metrics_weighted = compute_metrics(weighted_preds, weighted_probs) if weighted_preds is not None else None\n",
    "\n",
    "    # -----------------------------\n",
    "    # Print Results\n",
    "    # -----------------------------\n",
    "    print(\"\\n\\n **SOFT VOTING RESULTS**\")\n",
    "    for k, v in metrics_soft.items():\n",
    "        if k != \"confusion_matrix\":\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"\\n **HARD VOTING RESULTS**\")\n",
    "    for k, v in metrics_hard.items():\n",
    "        if k != \"confusion_matrix\":\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    if metrics_weighted is not None:\n",
    "        print(\"\\n **WEIGHTED VOTING RESULTS**\")\n",
    "        for k, v in metrics_weighted.items():\n",
    "            if k != \"confusion_matrix\":\n",
    "                print(f\"{k}: {v}\")\n",
    "\n",
    "    return {\n",
    "        \"metrics_soft\": metrics_soft,\n",
    "        \"metrics_hard\": metrics_hard,\n",
    "        \"metrics_weighted\": metrics_weighted,\n",
    "        \"soft_preds\": soft_preds,\n",
    "        \"soft_probs\": soft_probs,\n",
    "        \"hard_preds\": hard_preds,\n",
    "        \"weighted_preds\": weighted_preds\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "828f2b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\all_best_models\\\\best_model_fold_0.pt',\n",
       " '.\\\\all_best_models\\\\best_model_fold_1.pt',\n",
       " '.\\\\all_best_models\\\\best_model_fold_2.pt',\n",
       " '.\\\\all_best_models\\\\best_model_fold_3.pt',\n",
       " '.\\\\all_best_models\\\\best_model_fold_4.pt']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = '.\\\\all_best_models\\\\'\n",
    "file_paths = []\n",
    "for root, _, files in os.walk(directory_path):\n",
    "    for file in files:\n",
    "        file_paths.append(os.path.join(root, file))\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e30d0a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading model: .\\all_best_models\\best_model_fold_0.pt\n",
      "üì• Loading model: .\\all_best_models\\best_model_fold_1.pt\n",
      "üì• Loading model: .\\all_best_models\\best_model_fold_2.pt\n",
      "üì• Loading model: .\\all_best_models\\best_model_fold_3.pt\n",
      "üì• Loading model: .\\all_best_models\\best_model_fold_4.pt\n",
      "\n",
      "\n",
      "üéØ **SOFT VOTING RESULTS**\n",
      "loss: 0.7198155522346497\n",
      "accuracy: 0.8564206268958544\n",
      "precision: 0.49885057471264366\n",
      "recall: 0.7667844522968198\n",
      "f1: 0.6044568245125348\n",
      "roc_auc: 0.9034053597673475\n",
      "pr_auc: 0.6389007230901398\n",
      "\n",
      "üó≥Ô∏è **HARD VOTING RESULTS**\n",
      "loss: 0.7226370573043823\n",
      "accuracy: 0.8518705763397371\n",
      "precision: 0.48873873873873874\n",
      "recall: 0.7667844522968198\n",
      "f1: 0.5969738651994498\n",
      "roc_auc: 0.9034053597673475\n",
      "pr_auc: 0.6389007230901398\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_models_on_test_ensemble(\n",
    "    test_df=test_df,\n",
    "    model_paths= file_paths\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71094667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üó≥Ô∏è **HARD VOTING RESULTS**\n",
    "# loss: 0.7022083401679993\n",
    "# accuracy: 0.8842264914054601\n",
    "# precision: 0.5721925133689839\n",
    "# recall: 0.7561837455830389\n",
    "# f1: 0.6514459665144596\n",
    "# roc_auc: 0.9207417367647519\n",
    "# pr_auc: 0.708372352847281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c584483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "def save_and_plot_ensemble_results(\n",
    "    eval_results: Dict[str, Any],\n",
    "    ground_truth: np.ndarray,\n",
    "    output_folder: str = \"ensemble_results/\",\n",
    "    model_output_path: str = \"ensemble_final_model.pt\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates plots (confusion matrix, ROC, PR curve),\n",
    "    saves predictions, and exports the ensemble model.\n",
    "\n",
    "    Args:\n",
    "        eval_results      : Output of evaluate_models_on_test_ensemble()\n",
    "        ground_truth      : Numpy array of true labels\n",
    "        output_folder     : Directory to save images & CSV\n",
    "        model_output_path : File to save final ensemble soft-voting model weights\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Extract predictions\n",
    "    # -----------------------------\n",
    "    soft_probs = eval_results[\"soft_probs\"]\n",
    "    soft_preds = eval_results[\"soft_preds\"]\n",
    "    hard_preds = eval_results[\"hard_preds\"]\n",
    "    weighted_preds = eval_results[\"weighted_preds\"]\n",
    "\n",
    "    # =============================\n",
    "    #  1. Save predictions to CSV\n",
    "    # =============================\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"y_true\": ground_truth,\n",
    "        \"soft_prob\": soft_probs,\n",
    "        \"soft_pred\": soft_preds,\n",
    "        \"hard_pred\": hard_preds,\n",
    "        \"weighted_pred\": weighted_preds if weighted_preds is not None else np.nan\n",
    "    })\n",
    "\n",
    "    csv_path = os.path.join(output_folder, \"ensemble_predictions.csv\")\n",
    "    pred_df.to_csv(csv_path, index=False)\n",
    "    print(f\" Predictions saved to: {csv_path}\")\n",
    "\n",
    "    # =============================\n",
    "    #  2. Confusion Matrix Plot\n",
    "    # =============================\n",
    "    cm = confusion_matrix(ground_truth, soft_preds)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.imshow(cm, cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.xticks([0, 1])\n",
    "    plt.yticks([0, 1])\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, str(cm[i, j]), ha='center', va='center', color='red')\n",
    "\n",
    "    cm_path = os.path.join(output_folder, \"confusion_matrix.png\")\n",
    "    plt.savefig(cm_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\" Confusion Matrix saved to: {cm_path}\")\n",
    "\n",
    "    # =============================\n",
    "    #  3. ROC Curve Plot\n",
    "    # =============================\n",
    "    fpr, tpr, _ = roc_curve(ground_truth, soft_probs)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=\"ROC\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve (Soft Voting)\")\n",
    "    plt.legend()\n",
    "\n",
    "    roc_path = os.path.join(output_folder, \"roc_curve.png\")\n",
    "    plt.savefig(roc_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\" ROC Curve saved to: {roc_path}\")\n",
    "\n",
    "    # =============================\n",
    "    #  4. Precision‚ÄìRecall Curve\n",
    "    # =============================\n",
    "    precision, recall, _ = precision_recall_curve(ground_truth, soft_probs)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(recall, precision, label=\"Precision‚ÄìRecall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision‚ÄìRecall Curve (Soft Voting)\")\n",
    "    plt.legend()\n",
    "\n",
    "    pr_path = os.path.join(output_folder, \"pr_curve.png\")\n",
    "    plt.savefig(pr_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\" Precision‚ÄìRecall Curve saved to: {pr_path}\")\n",
    "\n",
    "    # =============================\n",
    "    #  5. Export Final Ensemble Model\n",
    "    # =============================\n",
    "\n",
    "    \"\"\"\n",
    "    Ensemble model: soft-voting means averaging probabilities.\n",
    "    You cannot save a single PyTorch state dict unless we create\n",
    "    a small wrapper module below.\n",
    "    \"\"\"\n",
    "\n",
    "    class SoftVotingEnsemble(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, prob_list):\n",
    "            \"\"\"\n",
    "            prob_list: tensor shape (num_models, batch_size)\n",
    "            \"\"\"\n",
    "            return prob_list.mean(dim=0)\n",
    "\n",
    "    ensemble_model = SoftVotingEnsemble()\n",
    "    torch.save(ensemble_model.state_dict(), model_output_path)\n",
    "\n",
    "    print(f\" Final Ensemble Model saved to: {model_output_path}\")\n",
    "\n",
    "    print(\"\\n ALL RESULTS SAVED SUCCESSFULLY!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad1af3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1973    0\n",
       "1974    0\n",
       "1975    0\n",
       "1976    0\n",
       "1977    0\n",
       "Name: window_label, Length: 1978, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['window_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b793e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Predictions saved to: ensemble_results/ensemble_predictions.csv\n",
      "üìä Confusion Matrix saved to: ensemble_results/confusion_matrix.png\n",
      "üìà ROC Curve saved to: ensemble_results/roc_curve.png\n",
      "üìâ Precision‚ÄìRecall Curve saved to: ensemble_results/pr_curve.png\n",
      "üß† Final Ensemble Model saved to: ensemble_final_soft_voting.pt\n",
      "\n",
      "üéâ ALL RESULTS SAVED SUCCESSFULLY!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ground_truth = test_df['window_label'].values  # or however your labels stored\n",
    "\n",
    "save_and_plot_ensemble_results(\n",
    "    eval_results=results,\n",
    "    ground_truth=ground_truth,\n",
    "    output_folder=\"ensemble_results/\",\n",
    "    model_output_path=\"ensemble_final_soft_voting.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b285025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae9273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
