{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f488a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset & DataLoader helpers\n",
    "# -----------------------------\n",
    "\n",
    "class FoGWindowDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for window-level FoG data.\n",
    "\n",
    "    Expects a DataFrame with columns:\n",
    "        - 'sequence'     : (T, 3) accel window (list/array/string)\n",
    "        - 'window_label' : 0/1\n",
    "        - 'subject'      : patient ID (not used in __getitem__, but kept in df)\n",
    "    \"\"\"\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def _parse_sequence(self, seq_obj):\n",
    "        # Handles numpy array, python list, or string from CSV\n",
    "        if isinstance(seq_obj, np.ndarray):\n",
    "            arr = seq_obj.astype(np.float32)\n",
    "        elif isinstance(seq_obj, list):\n",
    "            arr = np.asarray(seq_obj, dtype=np.float32)\n",
    "        else:\n",
    "            # assume string like \"[[...], [...], ...]\"\n",
    "            arr = np.array(ast.literal_eval(seq_obj), dtype=np.float32)\n",
    "\n",
    "        # Ensure shape (T, 3)\n",
    "        if arr.ndim == 1:\n",
    "            arr = arr.reshape(-1, 1)\n",
    "        return arr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        seq = self._parse_sequence(row['sequence'])  # (T, 3)\n",
    "        label = float(row['window_label'])\n",
    "\n",
    "        x = torch.from_numpy(seq)               # (T, 3)\n",
    "        y = torch.tensor(label, dtype=torch.float32)  # scalar 0/1\n",
    "        return x, y\n",
    "\n",
    "\n",
    "def make_dataloader(df: pd.DataFrame,\n",
    "                    batch_size: int = 64,\n",
    "                    shuffle: bool = True,\n",
    "                    num_workers: int = 0) -> DataLoader:\n",
    "    dataset = FoGWindowDataset(df)\n",
    "    loader = DataLoader(dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=shuffle,\n",
    "                        num_workers=num_workers)\n",
    "    return loader\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Patient-independent folds\n",
    "# -----------------------------\n",
    "\n",
    "def create_group_kfold_splits(df: pd.DataFrame,\n",
    "                              n_splits: int = 5,\n",
    "                              random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Patient-independent K-fold splits using GroupKFold on 'subject'.\n",
    "\n",
    "    Returns a list of (train_idx, val_idx) index arrays.\n",
    "    \"\"\"\n",
    "    groups = df['subject'].values\n",
    "    y = df['window_label'].values\n",
    "    X = np.arange(len(df))\n",
    "\n",
    "    gkf = GroupKFold(n_splits=n_splits)\n",
    "\n",
    "    # GroupKFold is deterministic; we can shuffle subjects before if needed:\n",
    "    # but simplest is to just use GroupKFold directly.\n",
    "    splits = list(gkf.split(X, y, groups))\n",
    "    return splits\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Metrics helper\n",
    "# -----------------------------\n",
    "\n",
    "def compute_metrics(y_true: np.ndarray,\n",
    "                    y_pred_probs: np.ndarray,\n",
    "                    threshold: float = 0.5) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute accuracy, precision, recall, F1 for binary classification.\n",
    "    \"\"\"\n",
    "    y_pred = (y_pred_probs >= threshold).astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average='binary', zero_division=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'accuracy': float(acc),\n",
    "        'precision': float(precision),\n",
    "        'recall': float(recall),\n",
    "        'f1': float(f1),\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# One epoch train / eval\n",
    "# -----------------------------\n",
    "\n",
    "def run_epoch(model: nn.Module,\n",
    "              loader: DataLoader,\n",
    "              criterion,\n",
    "              device: torch.device,\n",
    "              optimizer=None) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    If optimizer is provided: training mode.\n",
    "    Otherwise: evaluation mode.\n",
    "\n",
    "    Returns dict: loss, accuracy, precision, recall, f1\n",
    "    \"\"\"\n",
    "    if optimizer is None:\n",
    "        model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "    else:\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "    all_losses = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)              # (batch, T, 3)\n",
    "        y = y.to(device)              # (batch,)\n",
    "\n",
    "        logits = model(x)             # (batch,)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        if optimizer is not None:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        all_losses.append(loss.item())\n",
    "\n",
    "        probs = torch.sigmoid(logits)\n",
    "        all_probs.append(probs.detach().cpu().numpy())\n",
    "        all_labels.append(y.detach().cpu().numpy())\n",
    "\n",
    "    all_probs = np.concatenate(all_probs, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "\n",
    "    metrics = compute_metrics(all_labels, all_probs)\n",
    "    metrics['loss'] = float(np.mean(all_losses))\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Training one fold (with early stopping & scheduler)\n",
    "# -----------------------------\n",
    "\n",
    "def train_one_fold(\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    input_dim: int = 3,\n",
    "    hidden_dim: int = 128,\n",
    "    num_layers: int = 2,\n",
    "    bidirectional: bool = False,\n",
    "    dropout: float = 0.0,\n",
    "    batch_size: int = 16,\n",
    "    num_epochs: int = 50,\n",
    "    lr: float = 1e-4,\n",
    "    weight_decay: float = 1e-4,\n",
    "    early_stopping_patience: int = 7,\n",
    "    device: str = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Train LSTM on one fold with early stopping on val F1 and\n",
    "    ReduceLROnPlateau scheduler on val loss.\n",
    "\n",
    "    Returns:\n",
    "        dict with:\n",
    "            - 'best_state_dict'\n",
    "            - 'history' : list of per-epoch metrics\n",
    "    \"\"\"\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = make_dataloader(train_df, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = make_dataloader(val_df, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Model, loss, optimizer, scheduler\n",
    "    #model =  ParallelCNNLSTMTransformer().to(device)\n",
    "    # ---------------------------\n",
    "    # Quick test\n",
    "    # ---------------------------\n",
    "\n",
    "    B = 4\n",
    "    T = 256\n",
    "    C = 3\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    model = CNN_model().to(device)\n",
    "\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    #criterion = WeightedBCEWithLogitsLoss()\n",
    "    #criterion = FocalTverskyLoss(gamma=0.75, alpha=0.7)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5\n",
    "    )\n",
    "\n",
    "    best_val_f1 = -np.inf\n",
    "    best_state_dict = None\n",
    "    epochs_without_improvement = 0\n",
    "\n",
    "    history = []  # list of dicts per epoch\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # --- Train ---\n",
    "        train_metrics = run_epoch(model, train_loader, criterion, device, optimizer)\n",
    "\n",
    "        # --- Validation ---\n",
    "        val_metrics = run_epoch(model, val_loader, criterion, device, optimizer=None)\n",
    "\n",
    "        # Step scheduler on validation loss\n",
    "        scheduler.step(val_metrics['loss'])\n",
    "\n",
    "        # Early stopping on val F1\n",
    "        val_f1 = val_metrics['f1']\n",
    "        if val_f1 > best_val_f1:\n",
    "            best_val_f1 = val_f1\n",
    "            best_state_dict = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "            epochs_without_improvement = 0\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "\n",
    "        # Record metrics\n",
    "        epoch_record = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': train_metrics['loss'],\n",
    "            'train_accuracy': train_metrics['accuracy'],\n",
    "            'train_precision': train_metrics['precision'],\n",
    "            'train_recall': train_metrics['recall'],\n",
    "            'train_f1': train_metrics['f1'],\n",
    "            'val_loss': val_metrics['loss'],\n",
    "            'val_accuracy': val_metrics['accuracy'],\n",
    "            'val_precision': val_metrics['precision'],\n",
    "            'val_recall': val_metrics['recall'],\n",
    "            'val_f1': val_metrics['f1'],\n",
    "            'lr': optimizer.param_groups[0]['lr'],\n",
    "        }\n",
    "        history.append(epoch_record)\n",
    "\n",
    "        print(\n",
    "            f\"[Epoch {epoch:02d}] \"\n",
    "            f\"Train Loss={train_metrics['loss']:.4f}, Acc: {train_metrics['accuracy']:.4f}, F1={train_metrics['f1']:.4f} | \"\n",
    "\n",
    "            f\"Val Loss={val_metrics['loss']:.4f}, Acc: {val_metrics['accuracy']:.4f} F1={val_metrics['f1']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if epochs_without_improvement >= early_stopping_patience:\n",
    "            print(f\"Early stopping at epoch {epoch} (no val F1 improvement for \"\n",
    "                  f\"{early_stopping_patience} epochs).\")\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'best_state_dict': best_state_dict,\n",
    "        'history': history,\n",
    "    }\n",
    "\n",
    "def summarize_and_save_cv_results(\n",
    "        results: Dict[str, Any],\n",
    "        output_prefix: str = \"cv_results\",\n",
    "        save_best_model_path: str = \"best_model_overall.pt\",\n",
    "        save_all_folds_dir: str = \"all_best_models\"):\n",
    "    \"\"\"\n",
    "    - Extract best metrics from each fold\n",
    "    - Compute mean and std\n",
    "    - Save fold-wise results and summary to Excel\n",
    "    - Save ALL best model weights for all folds\n",
    "    - Save the global best model across folds\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    os.makedirs(save_all_folds_dir, exist_ok=True)\n",
    "\n",
    "    fold_best_rows = []\n",
    "    global_best_f1 = -np.inf\n",
    "    global_best_state_dict = None\n",
    "    global_best_fold = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # Extract best epoch per fold\n",
    "    # -----------------------------\n",
    "    for fold_data in results['folds']:\n",
    "        fold_idx = fold_data['fold_idx']\n",
    "        history = fold_data['history']\n",
    "\n",
    "        # Best epoch based on val_f1\n",
    "        best_epoch_record = max(history, key=lambda x: x['val_f1'])\n",
    "\n",
    "        row = {\n",
    "            'fold': fold_idx,\n",
    "            'val_accuracy': best_epoch_record['val_accuracy'],\n",
    "            'val_precision': best_epoch_record['val_precision'],\n",
    "            'val_recall': best_epoch_record['val_recall'],\n",
    "            'val_f1': best_epoch_record['val_f1'],\n",
    "            'val_loss': best_epoch_record['val_loss'],\n",
    "        }\n",
    "\n",
    "        fold_best_rows.append(row)\n",
    "\n",
    "        # ---------------------------------------\n",
    "        # Save THIS FOLD'S best model separately\n",
    "        # ---------------------------------------\n",
    "        fold_model_path = os.path.join(\n",
    "            save_all_folds_dir, f\"best_model_fold_{fold_idx}.pt\"\n",
    "        )\n",
    "        torch.save(fold_data['best_state_dict'], fold_model_path)\n",
    "        print(f\" Saved best model for Fold {fold_idx} ‚Üí {fold_model_path}\")\n",
    "\n",
    "        # ---------------------------------------\n",
    "        # Track the GLOBAL best model\n",
    "        # ---------------------------------------\n",
    "        if best_epoch_record['val_f1'] > global_best_f1:\n",
    "            global_best_f1 = best_epoch_record['val_f1']\n",
    "            global_best_state_dict = fold_data['best_state_dict']\n",
    "            global_best_fold = fold_idx\n",
    "\n",
    "    df_folds = pd.DataFrame(fold_best_rows)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Mean & Std\n",
    "    # -----------------------------\n",
    "    summary = {}\n",
    "    for col in ['val_accuracy', 'val_precision', 'val_recall', 'val_f1', 'val_loss']:\n",
    "        summary[f'{col}_mean'] = df_folds[col].mean()\n",
    "        summary[f'{col}_std'] = df_folds[col].std()\n",
    "\n",
    "    df_summary = pd.DataFrame([summary])\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save Excel files\n",
    "    # -----------------------------\n",
    "    folds_excel = f\"{output_prefix}_folds.xlsx\"\n",
    "    summary_excel = f\"{output_prefix}_summary.xlsx\"\n",
    "\n",
    "    df_folds.to_excel(folds_excel, index=False)\n",
    "    df_summary.to_excel(summary_excel, index=False)\n",
    "\n",
    "    print(f\" Fold metrics saved to Excel: {folds_excel}\")\n",
    "    print(f\" Summary metrics saved to Excel: {summary_excel}\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Save global best model\n",
    "    # -----------------------------\n",
    "    if global_best_state_dict is not None:\n",
    "        torch.save(global_best_state_dict, save_best_model_path)\n",
    "        print(f\"üèÜ Global best model (Fold {global_best_fold}) saved ‚Üí {save_best_model_path}\")\n",
    "\n",
    "    return {\n",
    "        'fold_metrics_df': df_folds,\n",
    "        'summary_df': df_summary,\n",
    "        'best_fold': global_best_fold,\n",
    "        'best_f1': global_best_f1\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Full K-fold cross-validation\n",
    "# -----------------------------\n",
    "\n",
    "def cross_validate_patient_independent(\n",
    "    df: pd.DataFrame,\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    "    **train_kwargs\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run patient-independent K-fold cross-validation.\n",
    "\n",
    "    Returns:\n",
    "        {\n",
    "          'folds': [\n",
    "            {\n",
    "              'fold_idx': 0,\n",
    "              'train_subjects': [...],\n",
    "              'val_subjects': [...],\n",
    "              'history': [...],           # list of per-epoch dicts\n",
    "              'best_state_dict': {...},\n",
    "            },\n",
    "            ...\n",
    "          ]\n",
    "        }\n",
    "    \"\"\"\n",
    "    splits = create_group_kfold_splits(df, n_splits=n_splits, random_state=random_state)\n",
    "\n",
    "    results = {'folds': []}\n",
    "\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(splits):\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Fold {fold_idx + 1}/{n_splits}\")\n",
    "\n",
    "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "        val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        train_subjects = sorted(train_df['subject'].unique())\n",
    "        val_subjects = sorted(val_df['subject'].unique())\n",
    "\n",
    "        print(f\"Train subjects (n={len(train_subjects)}): {train_subjects}\")\n",
    "        print(f\"Val subjects   (n={len(val_subjects)}): {val_subjects}\")\n",
    "        print(f\"Train windows: {len(train_df)}, Val windows: {len(val_df)}\")\n",
    "\n",
    "        fold_result = train_one_fold(\n",
    "            train_df=train_df,\n",
    "            val_df=val_df,\n",
    "            **train_kwargs\n",
    "        )\n",
    "\n",
    "        results['folds'].append({\n",
    "            'fold_idx': fold_idx,\n",
    "            'train_subjects': train_subjects,\n",
    "            'val_subjects': val_subjects,\n",
    "            'history': fold_result['history'],\n",
    "            'best_state_dict': fold_result['best_state_dict'],\n",
    "        })\n",
    "    #save the results:\n",
    "    summary = summarize_and_save_cv_results(\n",
    "        results,\n",
    "        output_prefix=\"fog_cv\",\n",
    "        save_best_model_path=\"best_fog_model.pt\"\n",
    "    )\n",
    "\n",
    "    results['summary'] = summary\n",
    "\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127ecf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# ===========================\n",
    "#   CNN Branch (unchanged order)\n",
    "# ===========================\n",
    "class CNNBranch(nn.Module):\n",
    "    def __init__(self, in_ch=3, channels=[64, 128, 128], kernel_size=5, skip=True):\n",
    "        super().__init__()\n",
    "        self.skip = skip\n",
    "        layers = []\n",
    "        ch = in_ch\n",
    "\n",
    "        for out_ch in channels:\n",
    "            layers.append(nn.Sequential(\n",
    "                nn.Conv1d(ch, out_ch, kernel_size, padding=kernel_size // 2),\n",
    "                nn.BatchNorm1d(out_ch),\n",
    "                nn.ReLU()\n",
    "            ))\n",
    "            ch = out_ch\n",
    "\n",
    "        self.blocks = nn.ModuleList(layers)\n",
    "        self.out_channels = ch\n",
    "\n",
    "        if skip and in_ch != ch:\n",
    "            self.skip_proj = nn.Conv1d(in_ch, ch, kernel_size=1)\n",
    "        else:\n",
    "            self.skip_proj = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, C, T)\n",
    "        residual_input = x\n",
    "        out = x\n",
    "\n",
    "        for block in self.blocks:\n",
    "            prev = out\n",
    "            out = block(out)\n",
    "            if self.skip and prev.shape == out.shape:\n",
    "                out = out + prev\n",
    "\n",
    "        if self.skip and self.skip_proj is not None:\n",
    "            residual_input = self.skip_proj(residual_input)\n",
    "            out = out + residual_input\n",
    "\n",
    "        return out  # (B, C, T)\n",
    "\n",
    "\n",
    "# ===========================\n",
    "#   Simple Attention Layer\n",
    "# ===========================\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.score_fc = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, F)\n",
    "        scores = self.score_fc(x)       # (B, T, 1)\n",
    "        weights = torch.softmax(scores, dim=1)  # (B, T, 1)\n",
    "        context = (weights * x).sum(dim=1)      # (B, F)\n",
    "        return context\n",
    "\n",
    "\n",
    "\n",
    "class CNN_model(nn.Module):\n",
    "    def __init__(self,\n",
    "                 seq_len=256,\n",
    "                 in_channels=3,\n",
    "                 cnn_channels=[32, 64, 128, 128],\n",
    "                 tcn_kernel=3,\n",
    "                 dropout=0.05):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN branch (1D CNN style)\n",
    "        self.cnn = CNNBranch(\n",
    "            in_ch=in_channels,\n",
    "            channels=cnn_channels,\n",
    "            kernel_size=tcn_kernel,\n",
    "            skip=True\n",
    "        )\n",
    "\n",
    "        # Attention pooling needs feature dim from CNN output\n",
    "        self.attention = AttentionLayer(hidden_dim=self.cnn.out_channels)\n",
    "\n",
    "        # Classifier MLP\n",
    "        self.pool_dropout = nn.Dropout(0.2)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(self.cnn.out_channels, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Expecting x: (B, C, T)\n",
    "        if x.dim() != 3:\n",
    "            raise ValueError(f\"Expected 3D input (B,C,T), got {x.shape}\")\n",
    "\n",
    "        # CNN needs channels-first ‚Üí already (B, C, T)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        c = self.cnn(x)  # (B, C, T)\n",
    "\n",
    "        # Attention expects (B, T, F)\n",
    "        c = c.permute(0, 2, 1)  # (B, T, C_feat)\n",
    "\n",
    "        context = self.attention(c)\n",
    "        context = self.pool_dropout(context)\n",
    "\n",
    "        out = self.mlp(context).squeeze(-1)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c179b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Student\\\\Desktop\\\\Abouhashem\\\\DeepLearningProject\\\\'\n",
    "train_df = pd.read_pickle(path+ \"FoG_windows_train.pkl\")\n",
    "test_df  = pd.read_pickle(path+\"FoG_windows_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17cc619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Fold 1/5\n",
      "Train subjects (n=32): ['07285e', '194d1d', '220a17', '231c3b', '24a59d', '251738', '2a39f8', '2c98f7', '31d269', '364459', '3b2403', '48fd62', '4b39ac', '4ca9b3', '4f13b4', '516a67', '54ee6e', '66341b', '7688c1', '79011a', '7eb666', '7fcee9', '8db7dd', '93f49f', 'a03db7', 'bc3908', 'c85fdf', 'c8e721', 'd8836b', 'd9312a', 'e8919c', 'f2c8aa']\n",
      "Val subjects   (n=2): ['2d57c2', '87174c']\n",
      "Train windows: 15896, Val windows: 3984\n",
      "[Epoch 01] Train Loss=0.5113, Acc: 0.7408, F1=0.1806 | Val Loss=0.8286, Acc: 0.5063 F1=0.6224\n",
      "[Epoch 02] Train Loss=0.4387, Acc: 0.7948, F1=0.5394 | Val Loss=1.2104, Acc: 0.3993 F1=0.5009\n",
      "[Epoch 03] Train Loss=0.3964, Acc: 0.8246, F1=0.6359 | Val Loss=0.8167, Acc: 0.5670 F1=0.6847\n",
      "[Epoch 04] Train Loss=0.3765, Acc: 0.8349, F1=0.6624 | Val Loss=1.0997, Acc: 0.3963 F1=0.4976\n",
      "[Epoch 05] Train Loss=0.3585, Acc: 0.8441, F1=0.6854 | Val Loss=0.8748, Acc: 0.5304 F1=0.6492\n",
      "[Epoch 06] Train Loss=0.3445, Acc: 0.8508, F1=0.7030 | Val Loss=0.6514, Acc: 0.6767 F1=0.7824\n",
      "[Epoch 07] Train Loss=0.3366, Acc: 0.8535, F1=0.7069 | Val Loss=0.7744, Acc: 0.6042 F1=0.7204\n",
      "[Epoch 08] Train Loss=0.3314, Acc: 0.8574, F1=0.7155 | Val Loss=0.8803, Acc: 0.5868 F1=0.7039\n",
      "[Epoch 09] Train Loss=0.3223, Acc: 0.8624, F1=0.7262 | Val Loss=0.8106, Acc: 0.6478 F1=0.7586\n",
      "[Epoch 10] Train Loss=0.3164, Acc: 0.8645, F1=0.7316 | Val Loss=1.1850, Acc: 0.4312 F1=0.5406\n",
      "[Epoch 11] Train Loss=0.3144, Acc: 0.8658, F1=0.7341 | Val Loss=0.8205, Acc: 0.6237 F1=0.7375\n",
      "[Epoch 12] Train Loss=0.3070, Acc: 0.8680, F1=0.7392 | Val Loss=0.7684, Acc: 0.6127 F1=0.7286\n",
      "[Epoch 13] Train Loss=0.2893, Acc: 0.8765, F1=0.7566 | Val Loss=0.7500, Acc: 0.6589 F1=0.7680\n",
      "Early stopping at epoch 13 (no val F1 improvement for 7 epochs).\n",
      "============================================================\n",
      "Fold 2/5\n",
      "Train subjects (n=26): ['07285e', '220a17', '24a59d', '2c98f7', '2d57c2', '31d269', '364459', '3b2403', '48fd62', '4b39ac', '4ca9b3', '516a67', '54ee6e', '66341b', '79011a', '7eb666', '7fcee9', '87174c', '8db7dd', '93f49f', 'a03db7', 'bc3908', 'c8e721', 'd8836b', 'd9312a', 'e8919c']\n",
      "Val subjects   (n=8): ['194d1d', '231c3b', '251738', '2a39f8', '4f13b4', '7688c1', 'c85fdf', 'f2c8aa']\n",
      "Train windows: 15880, Val windows: 4000\n",
      "[Epoch 01] Train Loss=0.4711, Acc: 0.7854, F1=0.6804 | Val Loss=0.7853, Acc: 0.6018 F1=0.2195\n",
      "[Epoch 02] Train Loss=0.3857, Acc: 0.8299, F1=0.7671 | Val Loss=0.7563, Acc: 0.6358 F1=0.2985\n",
      "[Epoch 03] Train Loss=0.3593, Acc: 0.8431, F1=0.7862 | Val Loss=0.6615, Acc: 0.6855 F1=0.4526\n",
      "[Epoch 04] Train Loss=0.3444, Acc: 0.8509, F1=0.7993 | Val Loss=0.7185, Acc: 0.6910 F1=0.4645\n",
      "[Epoch 05] Train Loss=0.3302, Acc: 0.8577, F1=0.8077 | Val Loss=0.4796, Acc: 0.7855 F1=0.6938\n",
      "[Epoch 06] Train Loss=0.3187, Acc: 0.8630, F1=0.8155 | Val Loss=0.5341, Acc: 0.7542 F1=0.6194\n",
      "[Epoch 07] Train Loss=0.3088, Acc: 0.8692, F1=0.8244 | Val Loss=0.6685, Acc: 0.7248 F1=0.5399\n",
      "[Epoch 08] Train Loss=0.3046, Acc: 0.8677, F1=0.8220 | Val Loss=0.6340, Acc: 0.7272 F1=0.5737\n",
      "[Epoch 09] Train Loss=0.2949, Acc: 0.8746, F1=0.8321 | Val Loss=0.6325, Acc: 0.7530 F1=0.6191\n",
      "[Epoch 10] Train Loss=0.2864, Acc: 0.8774, F1=0.8358 | Val Loss=0.4881, Acc: 0.7833 F1=0.6837\n",
      "[Epoch 11] Train Loss=0.2821, Acc: 0.8798, F1=0.8397 | Val Loss=0.6807, Acc: 0.7305 F1=0.5664\n",
      "[Epoch 12] Train Loss=0.2698, Acc: 0.8879, F1=0.8500 | Val Loss=0.5071, Acc: 0.7845 F1=0.6865\n",
      "Early stopping at epoch 12 (no val F1 improvement for 7 epochs).\n",
      "============================================================\n",
      "Fold 3/5\n",
      "Train subjects (n=26): ['194d1d', '220a17', '231c3b', '24a59d', '251738', '2a39f8', '2c98f7', '2d57c2', '31d269', '4b39ac', '4ca9b3', '4f13b4', '516a67', '7688c1', '79011a', '7eb666', '7fcee9', '87174c', '8db7dd', 'a03db7', 'bc3908', 'c85fdf', 'c8e721', 'd8836b', 'e8919c', 'f2c8aa']\n",
      "Val subjects   (n=8): ['07285e', '364459', '3b2403', '48fd62', '54ee6e', '66341b', '93f49f', 'd9312a']\n",
      "Train windows: 15909, Val windows: 3971\n",
      "[Epoch 01] Train Loss=0.5261, Acc: 0.7232, F1=0.6660 | Val Loss=0.5505, Acc: 0.7404 F1=0.3592\n",
      "[Epoch 02] Train Loss=0.4192, Acc: 0.8122, F1=0.7873 | Val Loss=0.5697, Acc: 0.7217 F1=0.3761\n",
      "[Epoch 03] Train Loss=0.3755, Acc: 0.8395, F1=0.8181 | Val Loss=0.4035, Acc: 0.8295 F1=0.3884\n",
      "[Epoch 04] Train Loss=0.3574, Acc: 0.8476, F1=0.8273 | Val Loss=0.4329, Acc: 0.7993 F1=0.4204\n",
      "[Epoch 05] Train Loss=0.3485, Acc: 0.8525, F1=0.8335 | Val Loss=0.3953, Acc: 0.8371 F1=0.3211\n",
      "[Epoch 06] Train Loss=0.3303, Acc: 0.8616, F1=0.8447 | Val Loss=0.4258, Acc: 0.8124 F1=0.3888\n",
      "[Epoch 07] Train Loss=0.3230, Acc: 0.8650, F1=0.8479 | Val Loss=0.4060, Acc: 0.8315 F1=0.3800\n",
      "[Epoch 08] Train Loss=0.3136, Acc: 0.8676, F1=0.8512 | Val Loss=0.4095, Acc: 0.8376 F1=0.3344\n",
      "[Epoch 09] Train Loss=0.3084, Acc: 0.8735, F1=0.8575 | Val Loss=0.4292, Acc: 0.8104 F1=0.3730\n",
      "[Epoch 10] Train Loss=0.2998, Acc: 0.8782, F1=0.8623 | Val Loss=0.4154, Acc: 0.8255 F1=0.3577\n",
      "[Epoch 11] Train Loss=0.2926, Acc: 0.8797, F1=0.8645 | Val Loss=0.4114, Acc: 0.8419 F1=0.3174\n",
      "Early stopping at epoch 11 (no val F1 improvement for 7 epochs).\n",
      "============================================================\n",
      "Fold 4/5\n",
      "Train subjects (n=26): ['07285e', '194d1d', '220a17', '231c3b', '251738', '2a39f8', '2c98f7', '2d57c2', '31d269', '364459', '3b2403', '48fd62', '4f13b4', '516a67', '54ee6e', '66341b', '7688c1', '7fcee9', '87174c', '93f49f', 'a03db7', 'bc3908', 'c85fdf', 'd9312a', 'e8919c', 'f2c8aa']\n",
      "Val subjects   (n=8): ['24a59d', '4b39ac', '4ca9b3', '79011a', '7eb666', '8db7dd', 'c8e721', 'd8836b']\n",
      "Train windows: 15916, Val windows: 3964\n",
      "[Epoch 01] Train Loss=0.5319, Acc: 0.7282, F1=0.6169 | Val Loss=0.4471, Acc: 0.8020 F1=0.6108\n",
      "[Epoch 02] Train Loss=0.3967, Acc: 0.8236, F1=0.7775 | Val Loss=0.4093, Acc: 0.8345 F1=0.7378\n",
      "[Epoch 03] Train Loss=0.3577, Acc: 0.8503, F1=0.8123 | Val Loss=0.3634, Acc: 0.8481 F1=0.7626\n",
      "[Epoch 04] Train Loss=0.3383, Acc: 0.8571, F1=0.8214 | Val Loss=0.3545, Acc: 0.8575 F1=0.7713\n",
      "[Epoch 05] Train Loss=0.3276, Acc: 0.8621, F1=0.8272 | Val Loss=0.3564, Acc: 0.8620 F1=0.7871\n",
      "[Epoch 06] Train Loss=0.3162, Acc: 0.8664, F1=0.8325 | Val Loss=0.3397, Acc: 0.8650 F1=0.7873\n",
      "[Epoch 07] Train Loss=0.3071, Acc: 0.8716, F1=0.8400 | Val Loss=0.3335, Acc: 0.8630 F1=0.7626\n",
      "[Epoch 08] Train Loss=0.3039, Acc: 0.8748, F1=0.8437 | Val Loss=0.3409, Acc: 0.8633 F1=0.7878\n",
      "[Epoch 09] Train Loss=0.2940, Acc: 0.8777, F1=0.8474 | Val Loss=0.3233, Acc: 0.8678 F1=0.7836\n",
      "[Epoch 10] Train Loss=0.2910, Acc: 0.8779, F1=0.8484 | Val Loss=0.3528, Acc: 0.8620 F1=0.7770\n",
      "[Epoch 11] Train Loss=0.2915, Acc: 0.8774, F1=0.8470 | Val Loss=0.3267, Acc: 0.8597 F1=0.7529\n",
      "[Epoch 12] Train Loss=0.2827, Acc: 0.8845, F1=0.8564 | Val Loss=0.3355, Acc: 0.8663 F1=0.7824\n",
      "[Epoch 13] Train Loss=0.2767, Acc: 0.8877, F1=0.8602 | Val Loss=0.3293, Acc: 0.8686 F1=0.7784\n",
      "[Epoch 14] Train Loss=0.2744, Acc: 0.8864, F1=0.8588 | Val Loss=0.3209, Acc: 0.8673 F1=0.7790\n",
      "[Epoch 15] Train Loss=0.2674, Acc: 0.8877, F1=0.8613 | Val Loss=0.3227, Acc: 0.8683 F1=0.7875\n",
      "Early stopping at epoch 15 (no val F1 improvement for 7 epochs).\n",
      "============================================================\n",
      "Fold 5/5\n",
      "Train subjects (n=26): ['07285e', '194d1d', '231c3b', '24a59d', '251738', '2a39f8', '2d57c2', '364459', '3b2403', '48fd62', '4b39ac', '4ca9b3', '4f13b4', '54ee6e', '66341b', '7688c1', '79011a', '7eb666', '87174c', '8db7dd', '93f49f', 'c85fdf', 'c8e721', 'd8836b', 'd9312a', 'f2c8aa']\n",
      "Val subjects   (n=8): ['220a17', '2c98f7', '31d269', '516a67', '7fcee9', 'a03db7', 'bc3908', 'e8919c']\n",
      "Train windows: 15919, Val windows: 3961\n",
      "[Epoch 01] Train Loss=0.5415, Acc: 0.7149, F1=0.6753 | Val Loss=0.5321, Acc: 0.7256 F1=0.4529\n",
      "[Epoch 02] Train Loss=0.4254, Acc: 0.8040, F1=0.7748 | Val Loss=0.5177, Acc: 0.7455 F1=0.5145\n",
      "[Epoch 03] Train Loss=0.3688, Acc: 0.8414, F1=0.8190 | Val Loss=0.4775, Acc: 0.7766 F1=0.5156\n",
      "[Epoch 04] Train Loss=0.3441, Acc: 0.8536, F1=0.8323 | Val Loss=0.4399, Acc: 0.7958 F1=0.5233\n",
      "[Epoch 05] Train Loss=0.3241, Acc: 0.8630, F1=0.8445 | Val Loss=0.4906, Acc: 0.7672 F1=0.5310\n",
      "[Epoch 06] Train Loss=0.3074, Acc: 0.8703, F1=0.8526 | Val Loss=0.4233, Acc: 0.8086 F1=0.4586\n",
      "[Epoch 07] Train Loss=0.3000, Acc: 0.8729, F1=0.8557 | Val Loss=0.3947, Acc: 0.8283 F1=0.6005\n",
      "[Epoch 08] Train Loss=0.2997, Acc: 0.8746, F1=0.8574 | Val Loss=0.5210, Acc: 0.7579 F1=0.5405\n",
      "[Epoch 09] Train Loss=0.2830, Acc: 0.8830, F1=0.8679 | Val Loss=0.3924, Acc: 0.8283 F1=0.5412\n",
      "[Epoch 10] Train Loss=0.2777, Acc: 0.8821, F1=0.8670 | Val Loss=0.4350, Acc: 0.7963 F1=0.5607\n",
      "[Epoch 11] Train Loss=0.2728, Acc: 0.8874, F1=0.8726 | Val Loss=0.4489, Acc: 0.7937 F1=0.5087\n",
      "[Epoch 12] Train Loss=0.2682, Acc: 0.8915, F1=0.8775 | Val Loss=0.4532, Acc: 0.7910 F1=0.5054\n",
      "[Epoch 13] Train Loss=0.2666, Acc: 0.8926, F1=0.8789 | Val Loss=0.4877, Acc: 0.7687 F1=0.5070\n",
      "[Epoch 14] Train Loss=0.2637, Acc: 0.8904, F1=0.8764 | Val Loss=0.3818, Acc: 0.8223 F1=0.5204\n",
      "Early stopping at epoch 14 (no val F1 improvement for 7 epochs).\n",
      "üìÅ Saved best model for Fold 0 ‚Üí all_best_models\\best_model_fold_0.pt\n",
      "üìÅ Saved best model for Fold 1 ‚Üí all_best_models\\best_model_fold_1.pt\n",
      "üìÅ Saved best model for Fold 2 ‚Üí all_best_models\\best_model_fold_2.pt\n",
      "üìÅ Saved best model for Fold 3 ‚Üí all_best_models\\best_model_fold_3.pt\n",
      "üìÅ Saved best model for Fold 4 ‚Üí all_best_models\\best_model_fold_4.pt\n",
      "‚úÖ Fold metrics saved to Excel: fog_cv_folds.xlsx\n",
      "‚úÖ Summary metrics saved to Excel: fog_cv_summary.xlsx\n",
      "üèÜ Global best model (Fold 3) saved ‚Üí best_fog_model.pt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cv_results = cross_validate_patient_independent(\n",
    "    train_df,\n",
    "    n_splits=5,\n",
    "    random_state=42,\n",
    "    input_dim=3,\n",
    "    hidden_dim=64,\n",
    "    num_layers=1,\n",
    "    bidirectional=False,\n",
    "    dropout=0.2,\n",
    "    batch_size=16,\n",
    "    num_epochs=50,\n",
    "    lr=1e-4,\n",
    "    weight_decay=1e-4,\n",
    "    early_stopping_patience=7,\n",
    "    device=None,  # auto: cuda if available else cpu\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e820ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, average_precision_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def evaluate_models_on_test_ensemble(\n",
    "    test_df: pd.DataFrame,\n",
    "    model_paths: List[str],\n",
    "    batch_size: int = 32,\n",
    "    device: str = None,\n",
    "    fold_weights: List[float] = None   # OPTIONAL for weighted voting\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Evaluate an ensemble of models on the test set using:\n",
    "        - Soft voting (default)\n",
    "        - Hard majority voting\n",
    "        - Optional weighted voting\n",
    "\n",
    "    Args:\n",
    "        test_df        : Test dataframe\n",
    "        model_paths    : List of paths to saved fold models\n",
    "        batch_size     : Test batch size\n",
    "        device         : 'cpu' or 'cuda'\n",
    "        fold_weights   : Optional weights per fold (e.g. fold F1)\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with all ensemble metrics and voting predictions\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------\n",
    "    # Device Setup\n",
    "    # -----------------------------\n",
    "    if device is None:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    # -----------------------------\n",
    "    # DataLoader\n",
    "    # -----------------------------\n",
    "    test_loader = make_dataloader(test_df, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    # collect predictions from each model\n",
    "    prob_list = []     # soft voting\n",
    "    hard_list = []     # hard voting\n",
    "    targets_list = []\n",
    "\n",
    "    # -----------------------------\n",
    "    # Load each model and predict\n",
    "    # -----------------------------\n",
    "    for idx, model_path in enumerate(model_paths):\n",
    "        if not os.path.exists(model_path):\n",
    "            raise FileNotFoundError(f\" Model not found: {model_path}\")\n",
    "\n",
    "        print(f\"üì• Loading model: {model_path}\")\n",
    "\n",
    "        model = CNN_model().to(device)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model.eval()\n",
    "\n",
    "        fold_probs = []\n",
    "        fold_hard = []\n",
    "        fold_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X, y in test_loader:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                logits = model(X)\n",
    "                probs = torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "\n",
    "                preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "                fold_probs.extend(probs)\n",
    "                fold_hard.extend(preds)\n",
    "                fold_targets.extend(y.cpu().numpy().astype(int))\n",
    "\n",
    "        prob_list.append(np.array(fold_probs))\n",
    "        hard_list.append(np.array(fold_hard))\n",
    "        targets_list = fold_targets     # same for all folds\n",
    "\n",
    "    prob_matrix = np.vstack(prob_list)     # shape: (num_models, N)\n",
    "    hard_matrix = np.vstack(hard_list)     # shape: (num_models, N)\n",
    "    ground_truth = np.array(targets_list)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Voting Methods\n",
    "    # -----------------------------\n",
    "\n",
    "    # SOFT VOTING (best default)\n",
    "    soft_probs = prob_matrix.mean(axis=0)\n",
    "    soft_preds = (soft_probs >= 0.5).astype(int)\n",
    "\n",
    "    # HARD VOTING\n",
    "    hard_preds = np.round(hard_matrix.mean(axis=0)).astype(int)\n",
    "\n",
    "    # WEIGHTED VOTING (if provided)\n",
    "    if fold_weights is not None:\n",
    "        w = np.array(fold_weights).reshape(-1, 1)\n",
    "        weighted_probs = (prob_matrix * w).sum(axis=0) / w.sum()\n",
    "        weighted_preds = (weighted_probs >= 0.5).astype(int)\n",
    "    else:\n",
    "        weighted_preds = None\n",
    "\n",
    "    # -----------------------------\n",
    "    # Metric Function\n",
    "    # -----------------------------\n",
    "    def compute_metrics(preds, probs=None):\n",
    "        return {\n",
    "            \"loss\": criterion(\n",
    "                torch.tensor(preds, dtype=torch.float32),\n",
    "                torch.tensor(ground_truth, dtype=torch.float32)\n",
    "            ).item(),\n",
    "            \"accuracy\": accuracy_score(ground_truth, preds),\n",
    "            \"precision\": precision_score(ground_truth, preds, zero_division=0),\n",
    "            \"recall\": recall_score(ground_truth, preds, zero_division=0),\n",
    "            \"f1\": f1_score(ground_truth, preds, zero_division=0),\n",
    "            \"roc_auc\": roc_auc_score(ground_truth, probs) if probs is not None else None,\n",
    "            \"pr_auc\": average_precision_score(ground_truth, probs) if probs is not None else None,\n",
    "            \"confusion_matrix\": confusion_matrix(ground_truth, preds)\n",
    "        }\n",
    "\n",
    "    # -----------------------------\n",
    "    # Compute Metrics\n",
    "    # -----------------------------\n",
    "    metrics_soft = compute_metrics(soft_preds, soft_probs)\n",
    "    metrics_hard = compute_metrics(hard_preds, soft_probs)\n",
    "    metrics_weighted = compute_metrics(weighted_preds, weighted_probs) if weighted_preds is not None else None\n",
    "\n",
    "    # -----------------------------\n",
    "    # Print Results\n",
    "    # -----------------------------\n",
    "    print(\"\\n\\n **SOFT VOTING RESULTS**\")\n",
    "    for k, v in metrics_soft.items():\n",
    "        if k != \"confusion_matrix\":\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    print(\"\\n **HARD VOTING RESULTS**\")\n",
    "    for k, v in metrics_hard.items():\n",
    "        if k != \"confusion_matrix\":\n",
    "            print(f\"{k}: {v}\")\n",
    "\n",
    "    if metrics_weighted is not None:\n",
    "        print(\"\\n **WEIGHTED VOTING RESULTS**\")\n",
    "        for k, v in metrics_weighted.items():\n",
    "            if k != \"confusion_matrix\":\n",
    "                print(f\"{k}: {v}\")\n",
    "\n",
    "    return {\n",
    "        \"metrics_soft\": metrics_soft,\n",
    "        \"metrics_hard\": metrics_hard,\n",
    "        \"metrics_weighted\": metrics_weighted,\n",
    "        \"soft_preds\": soft_preds,\n",
    "        \"soft_probs\": soft_probs,\n",
    "        \"hard_preds\": hard_preds,\n",
    "        \"weighted_preds\": weighted_preds\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "828f2b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\all_best_models\\\\best_model_fold_0.pt',\n",
       " '.\\\\all_best_models\\\\best_model_fold_1.pt',\n",
       " '.\\\\all_best_models\\\\best_model_fold_2.pt',\n",
       " '.\\\\all_best_models\\\\best_model_fold_3.pt',\n",
       " '.\\\\all_best_models\\\\best_model_fold_4.pt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path = '.\\\\all_best_models\\\\'\n",
    "file_paths = []\n",
    "for root, _, files in os.walk(directory_path):\n",
    "    for file in files:\n",
    "        file_paths.append(os.path.join(root, file))\n",
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e30d0a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Loading model: .\\all_best_models\\best_model_fold_0.pt\n",
      "üì• Loading model: .\\all_best_models\\best_model_fold_1.pt\n",
      "üì• Loading model: .\\all_best_models\\best_model_fold_2.pt\n",
      "üì• Loading model: .\\all_best_models\\best_model_fold_3.pt\n",
      "üì• Loading model: .\\all_best_models\\best_model_fold_4.pt\n",
      "\n",
      "\n",
      "üéØ **SOFT VOTING RESULTS**\n",
      "loss: 0.7099300622940063\n",
      "accuracy: 0.8619817997977756\n",
      "precision: 0.5157232704402516\n",
      "recall: 0.5795053003533569\n",
      "f1: 0.5457570715474209\n",
      "roc_auc: 0.8675213942483088\n",
      "pr_auc: 0.5526740578325077\n",
      "\n",
      "üó≥Ô∏è **HARD VOTING RESULTS**\n",
      "loss: 0.7107999920845032\n",
      "accuracy: 0.8609706774519716\n",
      "precision: 0.5123456790123457\n",
      "recall: 0.5865724381625441\n",
      "f1: 0.5469522240527183\n",
      "roc_auc: 0.8675213942483088\n",
      "pr_auc: 0.5526740578325077\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_models_on_test_ensemble(\n",
    "    test_df=test_df,\n",
    "    model_paths= file_paths\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71094667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üó≥Ô∏è **HARD VOTING RESULTS**\n",
    "# loss: 0.7022083401679993\n",
    "# accuracy: 0.8842264914054601\n",
    "# precision: 0.5721925133689839\n",
    "# recall: 0.7561837455830389\n",
    "# f1: 0.6514459665144596\n",
    "# roc_auc: 0.9207417367647519\n",
    "# pr_auc: 0.708372352847281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c584483",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, precision_recall_curve\n",
    "\n",
    "\n",
    "def save_and_plot_ensemble_results(\n",
    "    eval_results: Dict[str, Any],\n",
    "    ground_truth: np.ndarray,\n",
    "    output_folder: str = \"ensemble_results/\",\n",
    "    model_output_path: str = \"ensemble_final_model.pt\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates plots (confusion matrix, ROC, PR curve),\n",
    "    saves predictions, and exports the ensemble model.\n",
    "\n",
    "    Args:\n",
    "        eval_results      : Output of evaluate_models_on_test_ensemble()\n",
    "        ground_truth      : Numpy array of true labels\n",
    "        output_folder     : Directory to save images & CSV\n",
    "        model_output_path : File to save final ensemble soft-voting model weights\n",
    "    \"\"\"\n",
    "\n",
    "    import os\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Extract predictions\n",
    "    # -----------------------------\n",
    "    soft_probs = eval_results[\"soft_probs\"]\n",
    "    soft_preds = eval_results[\"soft_preds\"]\n",
    "    hard_preds = eval_results[\"hard_preds\"]\n",
    "    weighted_preds = eval_results[\"weighted_preds\"]\n",
    "\n",
    "    # =============================\n",
    "    #  1. Save predictions to CSV\n",
    "    # =============================\n",
    "    pred_df = pd.DataFrame({\n",
    "        \"y_true\": ground_truth,\n",
    "        \"soft_prob\": soft_probs,\n",
    "        \"soft_pred\": soft_preds,\n",
    "        \"hard_pred\": hard_preds,\n",
    "        \"weighted_pred\": weighted_preds if weighted_preds is not None else np.nan\n",
    "    })\n",
    "\n",
    "    csv_path = os.path.join(output_folder, \"ensemble_predictions.csv\")\n",
    "    pred_df.to_csv(csv_path, index=False)\n",
    "    print(f\" Predictions saved to: {csv_path}\")\n",
    "\n",
    "    # =============================\n",
    "    #  2. Confusion Matrix Plot\n",
    "    # =============================\n",
    "    cm = confusion_matrix(ground_truth, soft_preds)\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    plt.imshow(cm, cmap=\"Blues\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.xticks([0, 1])\n",
    "    plt.yticks([0, 1])\n",
    "\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j, i, str(cm[i, j]), ha='center', va='center', color='red')\n",
    "\n",
    "    cm_path = os.path.join(output_folder, \"confusion_matrix.png\")\n",
    "    plt.savefig(cm_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\" Confusion Matrix saved to: {cm_path}\")\n",
    "\n",
    "    # =============================\n",
    "    #  3. ROC Curve Plot\n",
    "    # =============================\n",
    "    fpr, tpr, _ = roc_curve(ground_truth, soft_probs)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(fpr, tpr, label=\"ROC\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve (Soft Voting)\")\n",
    "    plt.legend()\n",
    "\n",
    "    roc_path = os.path.join(output_folder, \"roc_curve.png\")\n",
    "    plt.savefig(roc_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\" ROC Curve saved to: {roc_path}\")\n",
    "\n",
    "    # =============================\n",
    "    #  4. Precision‚ÄìRecall Curve\n",
    "    # =============================\n",
    "    precision, recall, _ = precision_recall_curve(ground_truth, soft_probs)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    plt.plot(recall, precision, label=\"Precision‚ÄìRecall Curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision‚ÄìRecall Curve (Soft Voting)\")\n",
    "    plt.legend()\n",
    "\n",
    "    pr_path = os.path.join(output_folder, \"pr_curve.png\")\n",
    "    plt.savefig(pr_path, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\" Precision‚ÄìRecall Curve saved to: {pr_path}\")\n",
    "\n",
    "    # =============================\n",
    "    #  5. Export Final Ensemble Model\n",
    "    # =============================\n",
    "\n",
    "    \"\"\"\n",
    "    Ensemble model: soft-voting means averaging probabilities.\n",
    "    You cannot save a single PyTorch state dict unless we create\n",
    "    a small wrapper module below.\n",
    "    \"\"\"\n",
    "\n",
    "    class SoftVotingEnsemble(torch.nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, prob_list):\n",
    "            \"\"\"\n",
    "            prob_list: tensor shape (num_models, batch_size)\n",
    "            \"\"\"\n",
    "            return prob_list.mean(dim=0)\n",
    "\n",
    "    ensemble_model = SoftVotingEnsemble()\n",
    "    torch.save(ensemble_model.state_dict(), model_output_path)\n",
    "\n",
    "    print(f\"üß† Final Ensemble Model saved to: {model_output_path}\")\n",
    "\n",
    "    print(\"\\nüéâ ALL RESULTS SAVED SUCCESSFULLY!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad1af3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1973    0\n",
       "1974    0\n",
       "1975    0\n",
       "1976    0\n",
       "1977    0\n",
       "Name: window_label, Length: 1978, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['window_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b793e153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Predictions saved to: ensemble_results/ensemble_predictions.csv\n",
      "üìä Confusion Matrix saved to: ensemble_results/confusion_matrix.png\n",
      "üìà ROC Curve saved to: ensemble_results/roc_curve.png\n",
      "üìâ Precision‚ÄìRecall Curve saved to: ensemble_results/pr_curve.png\n",
      "üß† Final Ensemble Model saved to: ensemble_final_soft_voting.pt\n",
      "\n",
      "üéâ ALL RESULTS SAVED SUCCESSFULLY!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ground_truth = test_df['window_label'].values  # or however your labels stored\n",
    "\n",
    "save_and_plot_ensemble_results(\n",
    "    eval_results=results,\n",
    "    ground_truth=ground_truth,\n",
    "    output_folder=\"ensemble_results/\",\n",
    "    model_output_path=\"ensemble_final_soft_voting.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b285025",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae9273",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasaEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
